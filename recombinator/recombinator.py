""" Simulates the process of VDJ recombination """ 
import sys
import csv
import json
import random
import numpy
import math
import os
import re
from subprocess import check_output

from Bio import SeqIO
import dendropy

from utils.opener import opener
from utils import utils
from event import RecombinationEvent

#----------------------------------------------------------------------------------------
class Recombinator(object):
    """ Simulates the process of VDJ recombination """
    # TODO
    # bottlenecks:
    #    writing mute freqs and running bppseqgen five times for each recombination event

    def __init__(self, args, total_length_from_right=0):
        self.tmpdir = '/tmp/' + os.getenv('USER') + '/recombinator/' + str(os.getpid())
        utils.prep_dir(self.tmpdir)
        self.args = args
        # parameters that control recombination, erosion, and whatnot
        self.total_length_from_right = total_length_from_right  # measured from right edge of j, only write to file this much of the sequence (our read lengths are 130 by this def'n a.t.m.)
        self.hackey_extra_data_dir = 'recombinator/data'  # dir for tree parameters that I'm not yet inferring. TODO fix that, obviously
    
        self.all_seqs = {}  # all the Vs, all the Ds...
        self.index_keys = {}  # this is kind of hackey, but I suspect indexing my huge table of freqs with a tuple is better than a dict
        self.version_freq_table = {}  # list of the probabilities with which each VDJ combo appears in data
        self.mute_models = {}
        for region in utils.regions:
            self.mute_models[region] = {}
            for model in ['gtr', 'gamma']:
                self.mute_models[region][model] = {}

        # first read info that doesn't depend on which human we're looking at
        self.all_seqs = utils.read_germlines(self.args.datadir)
        with opener('r')(self.args.datadir + '/v-meta.json') as json_file:  # get location of <begin> cysteine in each v region
            self.cyst_positions = json.load(json_file)
        with opener('r')(self.args.datadir + '/j_tryp.csv') as csv_file:  # get location of <end> tryptophan in each j region (TGG)
            tryp_reader = csv.reader(csv_file)
            self.tryp_positions = {row[0]:row[1] for row in tryp_reader}  # WARNING: this doesn't filter out the header line

        # then read stuff that's specific to each human
        self.read_vdj_version_freqs(self.args.parameter_dir + '/' + utils.get_parameter_fname('all'))
        if self.args.naivety == 'M':  # read shm info if non-naive is requested
            # TODO I'm not inferring the gtr parameters a.t.m., so I'm just (very wrongly) using the same ones for all individuals
            with opener('r')(self.hackey_extra_data_dir + '/gtr.txt') as gtrfile:  # read gtr parameters
                reader = csv.DictReader(gtrfile)
                for line in reader:  # these files are generated with the command: [stoat] partis/ > zcat /shared/silo_researcher/Matsen_F/MatsenGrp/data/bcr/output_sw/A/04-A-M_gtr_tr-qi-gi.json.gz | jq .independentParameters | grep -v '[{}]' | sed 's/["\:,]//g' | sed 's/^[ ][ ]*//' | sed 's/ /,/' | sort >data/gtr.txt
                    parameters = line['parameter'].split('.')
                    region = parameters[0][3].lower()
                    assert region == 'v' or region == 'd' or region == 'j'
                    model = parameters[1].lower()
                    parameter_name = parameters[2]
                    assert model in self.mute_models[region]
                    self.mute_models[region][model][parameter_name] = line['value']
            with opener('r')(self.hackey_extra_data_dir + '/trees.tre') as treefile:  # read in the trees that were generated by tree-gen.r TODO don't get the trees from here
                self.trees = treefile.readlines()

        utils.prep_dir(self.args.outdir, 'simu.csv')

    # ----------------------------------------------------------------------------------------
    def combine(self):
        """ create a recombination event and write it to disk """
        if self.args.debug:
            print 'combine'
        reco_event = RecombinationEvent(self.all_seqs)
        self.choose_vdj_combo(reco_event)
        self.erode_and_insert(reco_event)
        if self.args.debug:
            print '  joining eroded seqs'
            print '         v: %s' % reco_event.eroded_seqs['v']
            print '    insert: %s' % reco_event.insertions['vd']
            print '         d: %s' % reco_event.eroded_seqs['d']
            print '    insert: %s' % reco_event.insertions['dj']
            print '         j: %s' % reco_event.eroded_seqs['j']
        reco_event.recombined_seq = reco_event.eroded_seqs['v'] + reco_event.insertions['vd'] + reco_event.eroded_seqs['d'] + reco_event.insertions['dj'] + reco_event.eroded_seqs['j']
        reco_event.set_final_tryp_position()

        if self.args.naivety == 'M':
            self.add_mutants(reco_event)  # toss a bunch of clones: add point mutations
        else:
            reco_event.final_seqs.append(reco_event.recombined_seq)

        if self.args.debug:
            reco_event.print_event(self.total_length_from_right)

        # write output to csv
        outfname = self.args.outdir + '/simu.csv'
        reco_event.write_event(outfname, self.total_length_from_right)

        os.rmdir(self.tmpdir)
        
        return True

    # ----------------------------------------------------------------------------------------
    def read_vdj_version_freqs(self, fname):
        """ Read the frequencies at which various VDJ combinations appeared in data """
        with opener('r')(fname) as infile:
            in_data = csv.DictReader(infile)
            total = 0.0
            for line in in_data:
                # NOTE do *not* assume the file is sorted
                if int(line['cdr3_length']) == -1:
                    continue  # couldn't find conserved codons when we were inferring things
                if self.args.only_genes != None:  # are we restricting ourselves to a subset of genes?
                    for region in utils.regions:
                        if line[region + '_gene'] not in self.args.only_genes: continue
                total += float(line['count'])
                index = tuple(line[column] for column in utils.index_columns)
                assert index not in self.version_freq_table
                self.version_freq_table[index] = float(line['count'])
            # then normalize
            test_total = 0.0
            for index in self.version_freq_table:
                self.version_freq_table[index] /= total
                test_total += self.version_freq_table[index]
            assert math.fabs(test_total - 1.0) < 1e-8

    # ----------------------------------------------------------------------------------------
    def choose_vdj_combo(self, reco_event):
        """ Choose which combination germline variants to use """
        iprob = numpy.random.uniform(0,1)
        sum_prob = 0.0
        for vdj_choice in self.version_freq_table:  # assign each vdj choice a segment of the interval [0,1], and choose the one which contains <iprob>
            sum_prob += self.version_freq_table[vdj_choice]
            if iprob < sum_prob:
                reco_event.set_vdj_combo(vdj_choice, self.cyst_positions, self.tryp_positions, self.all_seqs, debug=self.args.debug)
                return

        assert False  # shouldn't fall through to here

    # ----------------------------------------------------------------------------------------
    def erode(self, erosion, reco_event):
        """ apply <erosion> to the germline seqs in <reco_event> """
        seq = reco_event.eroded_seqs[erosion[0]]  # <erosion> looks like v_3p
        n_to_erode = reco_event.erosions[erosion]
        fragment_before = ''  # fragments to print
        fragment_after = ''
        if '5p' in erosion:
            fragment_before = seq[:n_to_erode + 3] + '...'
            new_seq = seq[n_to_erode:len(seq)]
            fragment_after = new_seq[:n_to_erode + 3] + '...'
        else:
            assert '3p' in erosion
            fragment_before = '...' + seq[len(seq) - n_to_erode - 3 :]
            new_seq = seq[0:len(seq)-n_to_erode]
            fragment_after = '...' + new_seq[len(new_seq) - n_to_erode - 3 :]

        if self.args.debug:
            print '    %3d from %s' % (n_to_erode, erosion[2:]),
            print 'of %s: %15s' % (erosion[0], fragment_before),
            print ' --> %-15s' % fragment_after
        if len(fragment_after) == 0:
            print '    NOTE eroded away entire sequence'

        reco_event.eroded_seqs[erosion[0]] = new_seq

    # ----------------------------------------------------------------------------------------
    def insert(self, boundary, reco_event):
        insert_seq_str = ''
        for _ in range(0, reco_event.insertion_lengths[boundary]):
            insert_seq_str += utils.int_to_nucleotide(random.randint(0, 3))  # TODO do something more accurate for the base content here
        reco_event.insertions[boundary] = insert_seq_str

    # ----------------------------------------------------------------------------------------
    def erode_and_insert(self, reco_event):
        """ Erode the germline seqs, and add insertions, based on the info in <reco_event> """
        if self.args.debug:
            print '  eroding'
        for region in utils.regions:
            reco_event.eroded_seqs[region] = reco_event.original_seqs[region]
        for erosion in utils.erosions:
            self.erode(erosion, reco_event)
        for boundary in utils.boundaries:
            self.insert(boundary, reco_event)

    # ----------------------------------------------------------------------------------------
    def write_mute_freqs(self, region, gene_name, seq, reco_event, reco_seq_fname, is_insertion=False):
        """ Read position-by-position mute freqs from disk for <gene_name>, renormalize, then write to a file for bppseqgen. """
        mute_freqs = {}
        mean_freq = 0.0  # calculate the mean mutation frequency. we'll use it for positions where we don't believe the actual number (eg too few alignments)
        if is_insertion:
            mean_freq = 0.1  # TODO don't pull this number outta yo ass
        else:
            # read mutation frequencies from disk. TODO this could be cached in memory to speed things up
            mutefname = self.args.parameter_dir + '/mute-freqs/' + utils.sanitize_name(gene_name) + '.csv'
            with opener('r')(mutefname) as mutefile:
                reader = csv.DictReader(mutefile)
                for line in reader:  # NOTE these positions are *zero* indexed
                    mute_freqs[int(line['position'])] = float(line['mute_freq'])
                    mean_freq += float(line['mute_freq'])
                mean_freq /= len(mute_freqs)  # TODO weight this calculation by the (inverse of the) uncertainty
    
        # calculate mute freqs for the positions in <seq>
        rates = []  # list with a mute freq for each position in <seq>
        total = 0.0
        # assert len(mute_freqs) == len(seq)  # only equal length if no erosions NO oh right but mute_freqs only covers areas we could align to...
        # TODO still, it'd be nice to have *some* way to make sure the position indices agree between mute_freqs and seq
        for inuke in range(len(seq)):  # append a freq for each nuke
            # NOTE be careful here! seqs are already eroded
            position = inuke
            if region == 'd' or region == 'j':
                position += reco_event.erosions[region + '_5p']

            freq = 0.0
            if position in mute_freqs:
                freq = mute_freqs[position]
            else:
                freq = mean_freq

            if region == 'v' and position < 200:  # don't really have any information here. TODO add some criterion to remove positions with really large uncertainties
                freq = mean_freq

            rates.append(freq)
            total += freq

        if total == 0.0:  # I am not yet hip enough to divide by zero
            print 'ERROR zero total frequency in %s (probably really an insert)' % mutefname
            assert False
        for inuke in range(len(seq)):  # normalize to the number of sites (this is how bppseqgen likes it)
            rates[inuke] *= float(len(seq)) / total
        total = 0.0
        for inuke in range(len(seq)):  # and... double check it, just for shits and giggles
            total += rates[inuke]
        assert utils.is_normed(total / float(len(seq)))
        assert len(rates) == len(seq)  # you just can't be too careful. what if gremlins ate a few while python wasn't looking?

        # write the input file for bppseqgen, one base per line
        with opener('w')(reco_seq_fname) as reco_seq_file:
            reco_seq_file.write('state\trate\n')
            for inuke in range(len(seq)):
                reco_seq_file.write('%s\t%.15f\n' % (seq[inuke], rates[inuke]))
                
        # TODO I need to find a tool to give me the total branch length of the chosen tree, so I can compare to the number of mutations I see

    # ----------------------------------------------------------------------------------------
    def run_bppseqgen(self, seq, chosen_tree, gene_name, reco_event, is_insertion=False):
        """ Run bppseqgen on sequence

        Note that this is in general a piece of the full sequence (say, the V region), since
        we have different mutation models for different regions. Returns a list of mutated
        sequences.
        """
        region = ''
        if is_insertion:
            region = 'v'  # TODO don't just use v for inserts
        else:
             region = utils.get_region(gene_name)

        if len(seq) == 0:  # zero length insertion (or d)
            treg = re.compile('t[0-9][0-9]*')  # find number of leaf nodes
            n_leaf_nodes = len(treg.findall(chosen_tree))
            return ['' for _ in range(n_leaf_nodes)]  # return an empty string for each leaf node

        # write the tree to a tmp file
        treefname = self.tmpdir + '/tree.tre'
        with opener('w')(treefname) as treefile:
            treefile.write(chosen_tree)

        reco_seq_fname = self.tmpdir + '/start_seq.txt'
        self.write_mute_freqs(region, gene_name, seq, reco_event, reco_seq_fname, is_insertion=is_insertion)

        leaf_seq_fname = self.tmpdir + '/leaf-seqs.fa'

        assert ';' not in self.args.bpp_dir
        assert os.path.exists(self.args.bpp_dir)  # NOTE you need a version of bio++ from at least 2014 for the mute-freqs-per-base to work. Either copy the binary from dkralph@gmail.com, or get a development version from: http://biopp.univ-montp2.fr/wiki/index.php/Installation

        # build up the command line
        command = 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:' + self.args.bpp_dir + '/lib\n'
        command += self.args.bpp_dir + '/bin/bppseqgen'
        command += ' input.tree.file=' + treefname
        command += ' output.sequence.file=' + leaf_seq_fname
        command += ' number_of_sites=' + str(len(seq))
        command += ' input.tree.format=Newick'
        command += ' output.sequence.format=Fasta\(\)'
        command += ' alphabet=DNA'
        command += ' --seed=' + str(os.getpid())
        command += ' model=GTR\('
        for par in self.mute_models[region]['gtr']:
            val = self.mute_models[region]['gtr'][par]
            command += par + '=' + val + ','
        command = command.rstrip(',')
        command += '\)'
        # TODO should I use the "equilibrium frequencies" option?
        command += ' rate_distribution=\'Gamma(n=4,alpha=' + self.mute_models[region]['gamma']['alpha']+ ')\''
        command += ' input.infos.states=state'
        command += ' input.infos=' + reco_seq_fname
        command += ' input.infos.rates=rate'
        check_output(command, shell=True)

        mutated_seqs = []
        for seq_record in SeqIO.parse(leaf_seq_fname, "fasta"):  # get the leaf node sequences from the file that bppseqgen wrote
            mutated_seqs.append(str(seq_record.seq))

        # self.check_tree_simulation(leaf_seq_fname, chosen_tree)

        os.remove(reco_seq_fname)  # clean up temp files
        os.remove(treefname)
        os.remove(leaf_seq_fname)

        return mutated_seqs

    # ----------------------------------------------------------------------------------------
    def add_mutants(self, reco_event):
        chosen_tree = self.trees[random.randint(0, len(self.trees)-1)]
        if self.args.debug:
            print '  generating mutations (seed %d) with tree %s' % (os.getpid(), chosen_tree)  # TODO make sure the distribution of trees you get *here* corresponds to what you started with before you ran it through treegenerator.py
        v_mutes = self.run_bppseqgen(reco_event.eroded_seqs['v'], chosen_tree, reco_event.genes['v'], reco_event, is_insertion=False)
        d_mutes = self.run_bppseqgen(reco_event.eroded_seqs['d'], chosen_tree, reco_event.genes['d'], reco_event, is_insertion=False)
        j_mutes = self.run_bppseqgen(reco_event.eroded_seqs['j'], chosen_tree, reco_event.genes['j'], reco_event, is_insertion=False)
        vd_mutes = self.run_bppseqgen(reco_event.insertions['vd'], chosen_tree, 'vd_insert', reco_event, is_insertion=True)  # TODO use a better mutation model for the insertions
        dj_mutes = self.run_bppseqgen(reco_event.insertions['dj'], chosen_tree, 'dj_insert', reco_event, is_insertion=True)

        assert len(reco_event.final_seqs) == 0
        for iseq in range(len(v_mutes)):
            seq = v_mutes[iseq] + vd_mutes[iseq] + d_mutes[iseq] + dj_mutes[iseq] + j_mutes[iseq]  # build final sequence
            seq = reco_event.revert_conserved_codons(seq)  # if mutation screwed up the conserved codons, just switch 'em back to what they were to start with
            reco_event.final_seqs.append(seq)  # set final sequnce in reco_event

        assert not utils.are_conserved_codons_screwed_up(reco_event)
        # print '    check full seq trees'
        # self.check_tree_simulation('', chosen_tree, reco_event)

    # ----------------------------------------------------------------------------------------
    def check_tree_simulation(self, leaf_seq_fname, chosen_tree_str, reco_event=None):
        """ See how well we can reconstruct the true tree """
        clean_up = False
        if leaf_seq_fname == '':  # we need to make the leaf seq file based on info in reco_event
            clean_up = True
            leaf_seq_fname = self.tmpdir + '/leaf-seqs.fa'
            with opener('w')(leaf_seq_fname) as leafseqfile:
                for iseq in range(len(reco_event.final_seqs)):
                    leafseqfile.write('>t' + str(iseq+1) + '\n')  # TODO the *order* of the seqs doesn't correspond to the tN number. does it matter?
                    leafseqfile.write(reco_event.final_seqs[iseq] + '\n')

        with opener('w')(os.devnull) as fnull:
            inferred_tree_str = check_output('FastTree -gtr -nt ' + leaf_seq_fname, shell=True, stderr=fnull)
        if clean_up:
            os.remove(leaf_seq_fname)
        chosen_tree = dendropy.Tree.get_from_string(chosen_tree_str, 'newick')
        inferred_tree = dendropy.Tree.get_from_string(inferred_tree_str, 'newick')
        if self.args.debug:
            print '        tree diff -- symmetric %d   euke %f   rf %f' % (chosen_tree.symmetric_difference(inferred_tree), chosen_tree.euclidean_distance(inferred_tree), chosen_tree.robinson_foulds_distance(inferred_tree))
