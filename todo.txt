  - compare other people\'s 'viterbi' codes
    - imgt/vquest: http://www.imgt.org/IMGT_vquest/vquest
    - ihmmunealign
    - soda[12]
    - joinsolver
  - write shit up!
    - first write outline and send to erick
    - instructions: http://royalsocietypublishing.org/instructions-authors#question6

  - figure out how you really want to treat base content in insertions
  - oops. data is here: /shared/silo_researcher/Matsen_F/MatsenGrp/data/bcr/data/r2/01-LMP-N
  - look at changing gcc options in stochhmm (-g, -02...)
  - get vdjalign running somewhere *other* than /home/dralph/.local/bin
  - remove out of frame and frame-shifted rearrangements?
  - change model file names .hmm -> .yaml
  - stop using hackey versions of gtr.txt and trees.tre in recombinator
  - remove seqs with stop codons?
  - will need to deal with productive and out-of-frame seqs separately, i.e. different parameters
  - account for different mutation frequencies to different bases
  - issue from erick: https://github.com/blab/immuno/issues/2
  - you\'re still writing some files for every query sequence in Stochhmm.cpp, I think. Don\'t!
  - if hamming distance is *very* small could precluster the *other* way, i.e. assume pairs are in the same event
  - would it be faster with STATE_MAX less than 1024?
  - why the hell is recombinator only spitting out clones with ten copies?
  - I should really be able to construct the denominator in P(A,B) / (P(A) P(B)) from the numerator without recalculating much, right?
  - add assertion in text parser that emission and transition probs add to 1.0
  - for k_v --> k_v + 1, don\'t recalculate the whole table
  - TODOs in code
  - transitivity:
    - rather than assuming transitivity in clustering, couldn\'t I use the extra information to improve clustering?
        (NOTE this is roughly equivalent to representing an existing cluster by its viterbi path. hm, with mutations or not?)

  - low priority
    - rewrite parsing code/text files with http://www.yaml.org/
    - optimization
      - hmm structure optimization
        - it seems like I should be able to take advantage of the fact that all my hmms are super linear, i.e. the matrix of possible transitions is very sparse
        - implement banding? I think I have this listed below but without using the word 'banding'
      - try pairwise s-w for preclustering (all against all -- align against each *other* using sw)
      - blast instead of s-w?
      - when we\'re doing pairs, it seems there should be some optimizations due to the fact we don\'t need to actually identify the gene versions, but only partition the sequences (EDIT wait, what?)
      - alleles: save chunks of dp tables and reuse \'em
    - accuracy improvement
      - play around with s-w match/mismatch scores (match was 3[:1], just changed to 2[:1]... not sure what\'s best. It\'ll depend on the expected level of mutation. *sigh*)
      - the choices we make about which is the best reconstruction near the d/insertions is very dependent on how much mutation we think occurred
        - so try to use the amount of mutation in v to inform this decision (?)
        - i.e., calculate the within-sequence correlation between V mutation and D/insertion mutation
    - wait, what is stochhmm doing with the 'N's?
    - add bfloats to stochhmm?


# ----------------------------------------------------------------------------------------
misc
  - connor\'s spectral decomposition sorting
  
simulator
  - make *sure* that the mute freqs are being properly used by the tree simulator
  - use amalgamation of patients (and each individually, with mature or naive)
  - better insertion freqs (nucleotide choices, at least)
  - better SHM freqs distribution
  - do something with tree inference closure tests for recombinator (?)
  - TODOs in recombinator
  - tree branch lengths per-person?
  data/simulation differences
    we ignore infrequent vdj choices, i.e. data has a *huge* tail of vdj choices with only a few instances which is totally absent in simulation
    mutation frequencies aren\'t site-dependent in simulation (yet!)
    not really sure that I\'m treating the primers correctly a.t.m.
    the plots I made so far are only for the first thousand lines in the data files
hmmer
  - only use half of data for training
