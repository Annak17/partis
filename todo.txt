- compare other people\'s 'viterbi' codes
    - convert recombinator csv to fasta: /home/dralph/Dropbox/bin/csv2fasta
    - compare also with simulation restricted to only a few v genes, i.e. to get the average correct fraction higher
    - programs
      - imgt/vquest: http://www.imgt.org/IMGT_vquest/vquest
      - ihmmunealign  2.6 sec/seq
      - soda[12]
      - joinsolver
  - write shit up!
    - instructions: http://royalsocietypublishing.org/instructions-authors#question6

  - add datadir option to vdjalign
  - NOTE forbidding unphysical deletions seems to have roughly the same performance, while improving run time by a factor of 6
  - clustering: do some heuristic preclustering, then for each of these clusters, use the n-hmm viterbi path, and cluster on these
  - remove this stuff in recombinator: 'if region == 'v' and position < 200:  # don\'t really have any information here. TODO add some criterion to remove positions with really large uncertainties'
  - account for different mutation frequencies to different bases
  - print a warning when the kbounds we pass to the hmm don\'t include the true one (and same thing for the gene versions)
  - check how close parameters are between data and simulation
  - account for non-uniform base content in insertions
    - don\'t forget to put this into recombinator  
  - optimize on fuzzes and n_max_per_region
  - looking at the damn plots, my insertions and deletions are on average too small. Why is this?
  - go through all of jobholder making sure I\'m not using query_strs.first instead of both, or instead of choosing the proper one
  - add testing framework to partis (include timing info)
    - short reads, long reads, reads with v left and j right erosions
    - single viterbi, viterbi pair, clustering
    - parameter estimation from sw and hmm
  - check orphaned state code in model.cc
  - stop using hackey versions of gtr.txt and trees.tre in recombinator. I.e. start inferring phylogenies
  - if hamming distance is *very* small could precluster the *other* way, i.e. assume pairs are in the same event
  - TODOs in code

  - low priority
    - will need to deal with productive and out-of-frame seqs separately, i.e. different parameters
    - disallow stop codons, out of frame and frame-shifted rearrangements in recombinator
    - do I really want to apply the gene choice prob in waterer?
    - optimization
      - would it be faster with STATE_MAX less than 1024?
        - for k_v --> k_v + 1, don\'t recalculate the whole table
      - run performance profiling
      - adding the gobbledygook states seems to have *really* slowed it down (EDIT oh, wait, that was just removing the gcc optimization options)
      - hmm structure optimization
        - it seems like I should be able to take advantage of the fact that all my hmms are super linear, i.e. the matrix of possible transitions is very sparse
        - implement banding? I think I have this listed below but without using the word 'banding'
      - try pairwise s-w for preclustering (all against all -- align against each *other* using sw)
    - I should really be able to construct the denominator in P(A,B) / (P(A) P(B)) from the numerator without recalculating much, right?
      - blast instead of s-w?
      - when we\'re doing pairs, it seems there should be some optimizations due to the fact we don\'t need to actually identify the gene versions, but only partition the sequences (EDIT wait, what?)
      - alleles: save chunks of dp tables and reuse \'em
    - accuracy improvement
      - play around with s-w match/mismatch scores (match was 3[:1], just changed to 2[:1]... not sure what\'s best. It\'ll depend on the expected level of mutation. *sigh*)
      - the choices we make about which is the best reconstruction near the d/insertions is very dependent on how much mutation we think occurred
        - so try to use the amount of mutation in v to inform this decision (?)
        - i.e., calculate the within-sequence correlation between V mutation and D/insertion mutation
    - clustering
      - use an N-HMM instead of a pair-HMM plus pairscore clustering
      - neighbor-joining
      - transitivity:
        - rather than assuming transitivity in clustering, couldn\'t I use the extra information to improve clustering?
            (NOTE this is roughly equivalent to representing an existing cluster by its viterbi path. hm, with mutations or not?)

# ----------------------------------------------------------------------------------------
misc
  - connor\'s spectral decomposition sorting
  
simulator
  - make *sure* that the mute freqs are being properly used by the tree simulator
  - use amalgamation of patients (and each individually, with mature or naive)
  - better insertion freqs (nucleotide choices, at least)
  - better SHM freqs distribution
  - do something with tree inference closure tests for recombinator (?)
  - TODOs in recombinator
  - tree branch lengths per-person?
  data/simulation differences
    we ignore infrequent vdj choices, i.e. data has a *huge* tail of vdj choices with only a few instances which is totally absent in simulation
    mutation frequencies aren\'t site-dependent in simulation (yet!)
    not really sure that I\'m treating the primers correctly a.t.m.
    the plots I made so far are only for the first thousand lines in the data files
hmmer
  - only use half of data for training


git remote add ham git@github.com:psathyrella/ham
git subtree add --squash --prefix packages/ham ham master

git remote add bpp git@github.com:psathyrella/bpp-master-20140414
git subtree add --squash --prefix packages/bpp bpp master

git remote add samtools git@github.com:samtools/samtools.git -t master
git subtree add --squash --prefix packages/samtools samtools master

git remote add ighutil git@github.com:cmccoy/ighutil.git -t master
git subtree add --squash --prefix packages/ighutil ighutil master

git remote add htslib git@github.com:samtools/htslib.git -t master
git subtree add --squash --prefix packages htslib htslib master --squash


